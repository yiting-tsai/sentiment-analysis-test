- Synthesio technical test
  - [âœ‹ How to get inference ?](#user-content--how-to-get-inference)
  - [ğŸ“š Methodology](#user-content--methodology)
  - [ğŸ‘“ Addition reading](#user-content--additional-reading)
  - [ğŸŒ³ Repo tree](#user-content--repo-tree)



## âœ‹ How to get inference ?
1. clone this repo `git clone https://github.com/yiting-tsai/sentiment-analysis-test.git`
2. get model weights from [google drive download link](https://drive.google.com/file/d/1zlsLILAYa_nekjEQ0VqstZ_2nX2iOqTI/view?usp=sharing) (logged in google account required)
    * because the model weight file exceeds 1GB and Git LFS doesn't support pushing LFS objects to public forks ([issue src link](https://github.com/git-lfs/git-lfs/issues/1906#issuecomment-276602035))
3. go to this repo and place the downloaded `tf_model.h5` to the folder of this repo `./model_weights_config/xlmr-model/`
4. create a virtual environment `virtualenv myEnv` and active `source myEnv/bin/activate`
5. install necessary python packages `pip install -r requirements`
6. run on terminal actual inference script `python xlmr-inference.py` (apprx. 10 mins to finish if on CPU)
7. inference results are saved in `predictions.csv` in the repo


## ğŸ“š Methodology
1. Understand the goal - multi-class classification on user-generated short comments in multiple languages
2. Understand the data - user-generated short comments in various lengths and in 17+ langugages
    - ğŸ‘ *please refer to data analytic notebook in `notebook/analytics/data_analytics.ipynb` for more details*
3. Understand the literature - multilingual embeddings (mBERT, XLM, XLM-RoBERTa, LASER, etc) via reading survey papers (ie [survey paper](https://arxiv.org/abs/2107.00676))
4. Modeling - two models : **XLM-R** (transfer learning) & **LASER + neural networks** (sentence embedding + classification model)
    - build the model 
    - choose `softmax` as activation on final layer for multi-class classification, 
    - choose ideal optimizer Adam, computationally efficient and handling well sparse grad on noisy problems
    - choose metrics accuracy, weighted f1 and Matthew correlation coefficients
    - set callbacks like early stopping to stop the model training if validation loss increases after 3 epochs in order to prevent overfitting on training data
    - efficient training on accelerators GPU and TPU on kaggle notebook
    - ğŸ‘ *please refer to individual train notebook/script of two models for more details*
5. Model analysis - black-box analysis on the performance resutls of the model
  - additional baseline model for comparison: zero-shot classification of XLM-R
    1. acc 0.52, F1 0.456, MCC 0.339
    2. both XLM-R and LASER+NN perform better than baseline model
  - **XLM-R**
    1. accurarcy reachs more than 80% within only 10 epochs
    2. posssible improvement:
      - add more layers to the down-stream task (I only use one layer)
      - increase data size
      - add text preprocessing to remove stopwords, punctuations or unnecessary tokens like `@username` or `#hashtag` (also removing `@username` for anonymization / privacy concern)
    3. XLM-R tokenizes with SentencePiece (language independent and data driven), which could be one of driven factors to its performance 
  - **LASER + NN**
    1. accurarcy reachs 80% after 50 epochs
    2. LASER performance degrades for shorter sentence because it was trained on sentences of at least 4 words [ref](https://github.com/facebookresearch/LASER/issues/44), and 15% of texts in training data is less than 25 characters, rather short sentence
    3. possible improvement:
      - specify on language when tokenizing for LASER with detected language info
      - apply batch normalization between layers in the NN
      - train more epochs
      - increase data size


### ğŸ‘“ Additional reading
1. XLM-R [paper](https://arxiv.org/abs/1911.02116)  /  [FacebookReseach blog](https://ai.facebook.com/blog/-xlm-r-state-of-the-art-cross-lingual-understanding-through-self-supervision/)
2. LASER [repo](https://github.com/facebookresearch/LASER)
3. Multilingual word embeddings 
  - [HuggingFace](https://huggingface.co/docs/transformers/multilingual)  
  - [A Primer on Pretrained Multilingual Language Models](https://arxiv.org/abs/2107.00676)  
  - [Unsupervised Cross-lingual Representation Learning at Scale](https://arxiv.org/abs/1911.02116)


## ğŸŒ³ Repo tree
```python
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ test.csv
â”‚Â Â  â””â”€â”€ train.csv
â”œâ”€â”€ LICENSE
â”œâ”€â”€ model_weights_config
â”‚Â Â  â”œâ”€â”€ laser-dnn-model
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ laser_model.h5
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ test_embedding.npy
â”‚Â Â  â”‚Â Â  â””â”€â”€ train_embedding.npy
â”‚Â Â  â””â”€â”€ xlmr-model
â”‚Â Â      â”œâ”€â”€ config.json
â”‚Â Â      â””â”€â”€ softmax.pickle
â”œâ”€â”€ notebook
â”‚Â Â  â”œâ”€â”€ analytics
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ data
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ analyzed_train.csv
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ lang_detect.csv
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ data_analytics.ipynb
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ model
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ laser_dnn_history.json
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ xlmr_history.json
â”‚Â Â  â”‚Â Â  â””â”€â”€ model_analytics.ipynb
â”‚Â Â  â”œâ”€â”€ inference
â”‚Â Â  â”‚Â Â  â””â”€â”€ xlmr-inferenc_.ipynb
â”‚Â Â  â””â”€â”€ train
â”‚Â Â      â”œâ”€â”€ laser-DNN_train_kaggle.ipynb
â”‚Â Â      â””â”€â”€ xlmr_train_kaggle.ipynb
â”œâ”€â”€ predictions.csv
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ script
â”‚Â Â  â”œâ”€â”€ train_laser-DNN_kaggle.py
â”‚Â Â  â””â”€â”€ train_xlmr_kaggle.py
â”œâ”€â”€ test-instructions.md
â””â”€â”€ xlmr-inference.py
```
